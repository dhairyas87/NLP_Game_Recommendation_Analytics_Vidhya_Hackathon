{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scare hear creepi voic paus moment write review wait heart beat return atleast somewhat calmer time game ador creepi like happi tree friend graphic sceme childhood bubbl clean hello charact isnot tri kill likabl bit odd noob thing though oh look class room full ghost dead children let shine flashlight stand stare hmm creepi music turn around see see chase never game afraid find lock door\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Keyu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#importing the dataset of the  training variables\n",
    "\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('train.csv')\n",
    "dataset\n",
    "\n",
    "\n",
    "#importing the nltk library for the natural language processing\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#removing the stopwords from the list of words created by review.\n",
    "#corpus ->a collection of written texts, especially the entire works of a particular author or a body of writing on a particular subject.\n",
    "\n",
    "\n",
    "from  nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "#Now apply stemming as each and every word has a root, and these roots are only used for getting to know the words\n",
    "#For example stem word for loved, loves,loving is love \n",
    "from  nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now to do this for each and every review \n",
    "#so make this corpus\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for i in range(0,len(dataset)):\n",
    "    review =  re.sub('[^a-zA-Z]',' ',dataset['user_review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = \" \".join(review)\n",
    "    corpus.append(review)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = dataset.iloc[:,-1].values\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 908  598]\n",
      " [ 263 1730]]\n"
     ]
    }
   ],
   "source": [
    "#Differentiating test set and cross valdition set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "\n",
    "#Implementing naive baiyes classification algorithm\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Predicting the output \n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "#Using the confusion matrix to predict the data is correct or not \n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
